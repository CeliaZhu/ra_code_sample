---
title: "Code Sample"
author: "Xiling Zhu"
date: "5/29/2020"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
pkg_list <- c("estimatr", "tidyverse", "stringr", "testthat", "lubridate", "gtsummary")
lapply(pkg_list, require, character.only = TRUE)

case <- read_csv("data/case.csv")
demo <- read.csv("data/demo.csv")
grades <- read.csv("data/grades.csv")
```

# Part 1: Data Management

1. The demographic data were extracted from a system that inconsistently coded gender. Recode it so that males are consistently coded as “M” and females are consistently coded as “F”.
```{r clean gender in demo, indent = "      ", results='hide'}
# Inconsistent encoding
demo %>%
  filter(gender != "M" & gender != "F") %>%
  distinct(gender)

# Clean "male", "female" encoding
demo_clean <- demo %>%
  mutate(
    gender = str_replace(gender, "^male$", "M"),
    gender = str_replace(gender, "^female$", "F")
  )

# Test that if there are inconsistent encoding
test_that(
  "Gender is consistently coded",
  expect_equal(
    0,
    nrow(demo_clean %>%
      filter(gender != "M" & gender != "F"))
  )
)
```

2. Merge the case and demo datasets together so that each row in the case dataset also
contains the demographics of the defendant. Keep in mind that the populations in the case and demo data may not be 100% aligned.

```{r further clean demo to merge with case, indent = "      "}
# person_id is the primary key in this join. Test if they conatin NAs
test_na <- function(df, x) {
  test_that(
    "No missing value in primary key person_id",
    expect_equal(
      0,
      nrow(df %>%
        filter(is.na(x)))
    )
  )
}
test_na(demo_clean, "person_id")
test_na(case, "person_id")

# Check if person_id is the unique identifier in demo_clean
# test_that(
#  "person_id is the unique identifier in demo",
#  expect_equal(
#    nrow(demo_clean),
#    nrow(demo_clean %>%
#           distinct(person_id)
#  )
# )
# )
# The test failed. person_id is not the unique identifier in demo. Extract duplicate person_id and see if they are in the case
duplicate_id <- demo_clean$person_id[duplicated(demo_clean$person_id)]

# There are 7739 observations in case that have duplicate person_id in demo_clean.
case %>%
  filter(person_id %in% duplicate_id)

# It would be problematic if we call join at this point. Further clean demo_clean. Remove duplicate rows
demo_clean <- unique(demo_clean)

# Check how many observations in cases do not have a match in demo
anti_join(case, demo_clean, by = "person_id")
```
```{r Merge demo and case, indent = "      "}
case_demo <- left_join(case, demo_clean, by = "person_id")

# Check that if the numbers of rows before and after join can match
test_that(
  "demo and case are merged correctly",
  expect_equal(
    nrow(case),
    nrow(case_demo)
  )
)
```


3. While the program was mostly rolled out to defendants in Chicago, the State’s Attorney’s Office also ran a pilot serving a small number of individuals arrested in other parts of Cook County. For the purpose of this analysis, please restrict the data to only individuals who were arrested in Chicago.


```{r restrict to Chicago, indent = "      "}
case_demo_chi <- case_demo %>%
  filter(endsWith(address, "CHICAGO") | endsWith(address, "Chicago") | endsWith(address, "chicago"))
```

# Part 2: Variable Creation

1. Create an age variable equal to the defendant’s age at the time of arrest for each case.
```{r age, indent = "      "}
case_demo_chi <- case_demo_chi %>%
    mutate(byear = year(ymd(bdate)), arrest_year = year(ymd(arrest_date))) %>%
    mutate(age = (arrest_year - byear)) 
```

2. The State’s Attorney is interested in pursuing a partnership with the Chicago Public Schools to investigate the relationship between high school achievement and criminal justice outcomes in early adulthood. To that end, the State’s Attorney’s Office has requested 9th and 10th grade course grade data from defendants between the ages of 18 and 24. These data are included in grades.csv. Please construct measures for 9th and 10th grade GPA for this target population. When constructing GPA, please use a 4 point scale, where: A=4, B=3, C=2, D=1, and F=0.

```{r grades, indent = "      "}
# Because grades data should not inform statistical analysis in part 3, I will not merge it with case
grades_clean <- grades %>%
  mutate_at(
    vars(starts_with("gr")),
    funs(case_when(
      . == "A" ~ 4,
      . == "B" ~ 3,
      . == "C" ~ 2,
      . == "D" ~ 1,
      . == "F" ~ 0
    ))
  )

for (i in 9:10) {
  grades_clean[, paste0("gpa", i)] <- rowMeans(select(grades_clean, starts_with(paste0("gr", i))), na.rm = TRUE)
}
```

# Part 3: Statistical Analysis

Help the State’s Attorney’s Office determine if the program should be continued/expanded by estimating the program’s effect on re-arrests prior to disposition. Because we only have grades data for young adults, please do not use these data to inform your statistical analysis. To draw conclusions about this program’s effect, answer the following questions.
```{r create analysis_data}
# Create a data set for statistical analysis
analysis_data <- case_demo_chi %>%
  mutate(black = (race == "BLACK"), asian = (race == "ASIAN"), white = (race == "WHITE")) %>%
  mutate(male = (gender == "M"), female = (gender == "F"))

# label data set to creat formatted tables
analysis_data <- expss::apply_labels(analysis_data,
  re_arrest = "Rearrested",
  prior_arrests = "Number of prior arrests",
  gender = "Gender",
  age = "Age",
  black = "Black",
  asian = "Asian",
  white = "White",
  male = "Male",
  female = "Female",
  treat = "Treatment",
  treat = c(
    "Treatment" = 1,
    "Control" = 0
  )
)

# Check that the study population has 25,000 subjects.
test_that(
  "The study population has 25,000 subjects",
  expect_equal(
    25000,
    nrow(analysis_data)
  )
)

# From now on I will use analysis_data for statistical analysis. Save the cleaned data.
saveRDS(analysis_data, "prepare_analysis_data/output/analysis_data.rds")
```

1. Describe the demographic characteristics of the study population based on the data available. (Hint: the study population has 25,000 subjects).

    There are 25000 subjects, or cases, in our sample. The average age is 30, and the average number of arrests before the case arrest data is 3.80. 73% of the cases are self-identified as Black. 80% of the cases self-identified as Male.
```{r summary statistics, indent = "      "}
# Descriptive statistics for demographic variables (output in html)
tbl_summary(
  analysis_data %>%
    select(black, asian, white, male, female, prior_arrests, age),
  statistic = list(all_continuous() ~ "{mean}({sd})")
) %>%
  as_gt()
```

2.

a. Are the treatment and control groups balanced (on race, gender, etc.), or are there differences in the composition of the two groups? Please present your answer in the form of a table.

    The treatment and control groups are not balanced. The average numbers of arrests prior to the case arrest date are significantly different in two groups. Cases with more prior arrests are more likely to be treated. The age characteristic is also imbalanced. Older cases are more likely to be treated. It signals the existence of self-selection.
```{r baseline equivalence, indent = "      "}
# Balance table of covariates
balancevar <- analysis_data %>%
  select(prior_arrests, age, treat, black, asian, white, male, female)

tbl_summary(
  balancevar,
  by = treat, 
  statistic = list(all_continuous() ~ "{mean}({sd})")
) %>%
  add_p() %>%
  as_gt()
```

b. Choose one observable characteristic and visualize the difference between those who were enrolled in the program and those who were not.
```{r plot, indent = "      "}
fill_pal <- rep(c("#800000E6", "#800000B3", "#80000080"), times = 3)
sig_levl <- 0.05

analysis_data %>%
  group_by(treat, race) %>%
  summarise(
    avg_arrests = mean(prior_arrests),
    sd = sd(prior_arrests),
    n = n()
  ) %>%
  mutate(ci = 1.96 * (sd / sqrt(n))) %>%
  ungroup() %>%
  mutate(
    plot_id = c(1, 2, 3, 5, 6, 7),
    fill_pal = rep(c("#800000E6", "#800000B3", "#80000080"), times = 2)
  ) %>%
  ggplot() +
  geom_col(aes(x = plot_id, y = avg_arrests, fill = race), position = "dodge") +
  scale_fill_manual(values = fill_pal, name = "Race", labels = c("Asian", "Black", "White")) +
  geom_errorbar(aes(x = plot_id, ymin = avg_arrests - ci, ymax = avg_arrests + ci), width = 0.2, colour = "#666666", alpha = 0.9, size = 1) +
  scale_x_continuous(breaks = c(2, 6), label = c("Unenrolled", "Enrolled")) +
  labs(
    x = "Enrollment status",
    y = "Average number of prior arrests",
    title = "Number of prior arrests is imbalanced between enrolled and unenrolled group",
    subtitle = "Average number of prior arrests and 95% confidence interval by race and enrollment status",
    caption = "Source: Cook County State's Attorney's Office"
  ) +
  theme_minimal()
```

3. Did participating in the program reduce the likelihood of re-arrest before disposition? Explain your answer and your methodology.

    We can conclude that participating in the program reduced the likelihood of re-arrest before disposition.

    From the comparison of characteristics in Part 3 2.a and the visualization in 2.b, we show that the treatment or control group are imblanced. Especially, the number of prior arrests and age are imbalanced. It signals that there exists self-selection. To estimate the treatment effect despite the possible existence of self-selection, I used three specifications.

    **1. OLS (or Linear Probability Model)**

    The first one is a "naive" OLS model with robust standard error.
$$
		rearrest_{ic} = \tau treat_{ic} + \beta_1 priorarrests_{ic} + \beta_2 gender_{ic} + \beta_3 race_{ic} + \beta_4 age_{ic} + \epsilon_{ic}
$$
    where $i$ is the individual and $c$ is the case.

    It can correctly estimate the treatment effect given that 1) there is no selection on unobservables and we've controlled all observables that could be selected upon; and 2) how people are self-selected based on those variables can be approximated by a linear function. But these assumptions are unlikely to be true. Nevertheless, we show there is a correlation between treatment and the reduction of re-arrests, and the coefficient is significantly different from zero at a significance level of 5%.

    One problem however, is that when I included individual fixed effects, the coefficient of treatment is not significantly different from zero. It might be related to the sample size within unit (i.e., the number of cases of one individual). But OLS specification is overall naive in this scenario. We can obtain more plausible estimation in specification 2 and 3.

    **2. Logit Model**

    The first specification, however, is also a linear probability model as our outcome variable is binary. We can improve this by using a logit model Assuming:
$$
  Pr(rearrest = 1 | X_c) = \frac{exp^{X_c'\beta}}{1 + e^{X_c'\beta}}
$$

    where $X_c$ are prior arrests, gender, race, and age of the case $c$. In the logit model the treatment significantly reduces the likelyhood of rearrest.


    **3. Weighted Propensity Score Matching**

    The third specification is a weighted propensity score matching. To estimate the treatment effect, we need to assume that there is no selection on unobservables and we've controlled all observables that could be selected upon. However, we can relax the assumption on the functional form. The estimate based upon propensity score is not entirely valid, because we omit variables such as grades, household income, etc.. However, this is less restrictive and therefore more credible than the OLS estimate. In propensity score matchig, he treatment also significantly reduces the likelihood of rearrest.
```{r estimate treatment effect, indent = "      "}
# Specification 1: OLS
ols <- lm_robust(re_arrest ~ treat + prior_arrests + gender + race + age, data = analysis_data)
tb1 <- tbl_regression(ols)

# Specification 2: logit
logit <- glm(re_arrest ~ treat + prior_arrests + gender + race + age, data = analysis_data, family = binomial)
tb2 <- tbl_regression(logit)

# Specification 3: Propensity score matching (weighting)
pscore_estimate <- glm(treat ~ prior_arrests + gender + race + age, data = analysis_data, family = binomial)
pscore <- predict(pscore_estimate, type = "response")

analysis_data$pscore <- pscore

analysis_data$ate_weight <- if_else(analysis_data$treat == 1, (1 / analysis_data$pscore), (1 / (1 - analysis_data$pscore)))
analysis_data$atet_weight <- if_else(analysis_data$treat == 1, 1, (analysis_data$pscore / (1 - analysis_data$pscore)))

psm_ate <- glm(re_arrest ~ treat, data = analysis_data, weights = ate_weight, family = binomial)
psm_atet <- glm(re_arrest ~ treat, data = analysis_data, weights = atet_weight, family = binomial)
tb3 <- tbl_regression(psm_ate)
tb4 <- tbl_regression(psm_atet)

# Merge regression table
tbl_merge(list(tb1, tb2, tb3, tb4), tab_spanner = c("OLS ", "Logit", "Weighted Propensity Score Matching (ATE)", "Weighted Propensity Score Matching (ATET)"))
```

## Conclusion and Discussion

Overall, the treatment significantly reduces the likelihood of re-arrest before disposition. With the information we have, we can conclude that the program is effective and should be expanded or continued, or should be furthered examined with an RCT.

However, please note that the causal inference has much room for improvement. It would have better performance if we can obtain more relevant variables. For example, their grades, household income, neighboorhoods. We would also be able to employ more plausible causal inference methods if we could obtain pre-treatment information on the individuals.
