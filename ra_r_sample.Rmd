---
title: "R Code Sample"
author: "Xiling Zhu <xiling@uchicago.edu>"
date: "Aug 28, 2020"
output: html_document
---

## Background

In January 2012, the Cook County State’s Attorney’s Office established a program intended to reduce re-arrest among people on bail awaiting trial.
The program ran through October 2013.

The objective of our analysis is to evaluate the effectiveness of the program. We start by cleaning data sets on demographics, cases, and academic performance.
Next we proceed to provide descriptive statistics for the study population and test their baseline equivalence. The final step is to evaluate whether
participating in the program reduces the likelihood of re-arrest before disposition.

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
pkg_list <- c("estimatr", "tidyverse", "stringr", "testthat", "lubridate", "gtsummary", "fastDummies")
lapply(pkg_list, require, character.only = TRUE)

case <- read_csv("data/case.csv")
demo <- read.csv("data/demo.csv")
grades <- read.csv("data/grades.csv")
```

## 1 Data Cleaning

### 1.1 Clean demographic data

The demographic data were extracted from a system that inconsistently coded gender. Recode it so that males are consistently coded as “M” and females are consistently coded as “F”.

```{r clean gender in demo}
# Inconsistent encoding
  demo %>%
  filter(gender != "M" & gender != "F") %>%
  distinct(gender) 

# Clean "male", "female" encoding
demo_clean <- demo %>%
  mutate(
    gender = str_replace(gender, "^male$", "M"),
    gender = str_replace(gender, "^female$", "F")
  )

# Test that if there are inconsistent encoding
test_that(
  "Gender is consistently coded",
  expect_equal(
    0,
    nrow(demo_clean %>%
      filter(gender != "M" & gender != "F"))
  )
)
```

### 1.2 Clean case data 

Merge the case and demo datasets together so that each row in the case dataset also contains the demographics of the defendant. Keep in mind that the populations in the case and demo data may not be 100% aligned.

```{r further clean demo to merge with case}
# person_id is the primary key in this join. Test if they conatin NAs
test_na <- function(df, x) {
  test_that(
    "No missing value in primary key person_id",
    expect_equal(
      0,
      nrow(df %>%
        filter(is.na(x)))
    )
  )
}
test_na(demo_clean, "person_id")
test_na(case, "person_id")

# Check if person_id is the unique identifier in demo_clean
# test_that(
#  "person_id is the unique identifier in demo",
#  expect_equal(
#    nrow(demo_clean),
#    nrow(demo_clean %>%
#           distinct(person_id)
#  )
# )
# )

# The test failed. person_id is not the unique identifier in demo. Extract duplicate person_id and see if they are in the case
# It would be problematic if we call join at this point. Further clean demo_clean. Remove duplicate rows
demo_clean <- unique(demo_clean)

# Check how many observations in cases do not have a match in demo
anti_join(case, demo_clean, by = "person_id")
```
```{r Merge demo and case}
case_demo <- left_join(case, demo_clean, by = "person_id")

# Check that if the numbers of rows before and after join can match
test_that(
  "demo and case are merged correctly",
  expect_equal(
    nrow(case),
    nrow(case_demo)
  )
)
```


While the program was mostly rolled out to defendants in Chicago, the State’s Attorney’s Office also ran a pilot serving a small number of individuals arrested in other parts of Cook County. For the purpose of this analysis, please restrict the data to only individuals who were arrested in Chicago.

```{r restrict to Chicago}
case_demo_chi <- case_demo %>%
  filter(endsWith(address, "CHICAGO") | endsWith(address, "Chicago") | endsWith(address, "chicago"))
```

Create an age variable equal to the defendant’s age at the time of arrest for each case.
```{r age}
case_demo_chi <- case_demo_chi %>%
    mutate(byear = year(ymd(bdate)), arrest_year = year(ymd(arrest_date))) %>%
    mutate(age = (arrest_year - byear))
```

### 1.3 Clean grades data

The State’s Attorney is interested in pursuing a partnership with the Chicago Public Schools to investigate the relationship between high school achievement and criminal justice outcomes in early adulthood. To that end, the State’s Attorney’s Office has requested 9th and 10th grade course grade data from defendants between the ages of 18 and 24. These data are included in grades.csv. Please construct measures for 9th and 10th grade GPA for this target population. When constructing GPA, please use a 4 point scale, where: A=4, B=3, C=2, D=1, and F=0.

```{r grades}
# Because grades data should not inform statistical analysis in part 3, I will not merge it with case
grades_clean <- grades %>%
  mutate_at(
    vars(starts_with("gr")),
    funs(case_when(
      . == "A" ~ 4,
      . == "B" ~ 3,
      . == "C" ~ 2,
      . == "D" ~ 1,
      . == "F" ~ 0
    ))
  )

for (i in 9:10) {
  grades_clean[, paste0("gpa", i)] <- rowMeans(select(grades_clean, starts_with(paste0("gr", i))), na.rm = TRUE)
}
```

## 2: Statistical Analysis

Help the State’s Attorney’s Office determine if the program should be continued/expanded by estimating the program’s effect on re-arrests prior to disposition. Because we only have grades data for young adults, please do not use these data to inform your statistical analysis. 
```{r prepare for creating dummies}
# Check distinct values of race. 
case_demo_chi %>%
  distinct(race) 
```


```{r create analysis data}
# Create dummies for statistical analysis
analysis_data <- case_demo_chi %>%
  dummy_cols(select_columns = c("race", "gender")) %>% 
  rename(asian = race_ASIAN, black = race_BLACK, white = race_WHITE, 
         female = gender_F, male = gender_M)

# label data set to creat formatted tables
analysis_data <- expss::apply_labels(analysis_data,
  re_arrest = "Rearrested",
  prior_arrests = "Number of prior arrests",
  gender = "Gender",
  age = "Age",
  race = "Race",
  black = "Black",
  asian = "Asian",
  white = "White",
  male = "Male",
  female = "Female",
  treat = "Treatment",
  treat = c(
    "Enrolled" = 1,
    "Unenrolled" = 0
  )
)

# Check that the study population has 25,000 subjects.
test_that(
  "The study population has 25,000 subjects",
  expect_equal(
    25000,
    nrow(analysis_data)
  )
)

# From now on I will use analysis_data for statistical analysis. Save the cleaned data.
saveRDS(analysis_data, "output/analysis_data.rds")
```

### 2.1 Summary statistics of study population

```{r summary statistics}
# Descriptive statistics for demographic variables (output in html)
tbl_summary(
  analysis_data %>%
    select(black, asian, white, male, female, prior_arrests, age),
  statistic = list(all_continuous() ~ "{mean}({sd})")
) %>%
  as_gt()
```

### 2.2 Balance tests for demographic characteristics

The treatment and control groups are not balanced. The average numbers of arrests prior to the case arrest date are significantly different in two groups. Cases with more prior arrests are more likely to be treated. The age characteristic is also imbalanced. Older cases are more likely to be treated. It signals the existence of selection.
    
```{r baseline equivalence}
# Balance table of covariates
balancevar <- analysis_data %>%
  select(prior_arrests, age, treat, black, asian, white, male, female)

tbl_summary(
  balancevar,
  by = treat,
  statistic = list(all_continuous() ~ "{mean}({sd})")
) %>%
  add_p() %>%
  as_gt()
```

### 2.3 Visualize number of prior arrests by enrollment status and race

```{r plot}
fill_pal <- rep(c("#800000E6", "#800000B3", "#80000080"), times = 3)
sig_levl <- 0.05

analysis_data %>%
  group_by(treat, race) %>%
  summarise(
    avg_arrests = mean(prior_arrests),
    sd = sd(prior_arrests),
    n = n()
  ) %>%
  mutate(ci = 1.96 * (sd / sqrt(n))) %>%
  ungroup() %>%
  mutate(
    plot_id = c(1, 2, 3, 5, 6, 7),
    fill_pal = rep(c("#800000E6", "#800000B3", "#80000080"), times = 2)
  ) %>%
  ggplot() +
  geom_col(aes(x = plot_id, y = avg_arrests, fill = race), position = "dodge") +
  scale_fill_manual(values = fill_pal, name = "Race", labels = c("Asian", "Black", "White")) +
  geom_errorbar(aes(x = plot_id, ymin = avg_arrests - ci, ymax = avg_arrests + ci), width = 0.2, colour = "#666666", alpha = 0.9, size = 1) +
  scale_x_continuous(breaks = c(2, 6), label = c("Unenrolled", "Enrolled")) +
  labs(
    x = "Enrollment status",
    y = "Average number of prior arrests",
    title = "Number of prior arrests is imbalanced between enrolled and unenrolled group",
    subtitle = "Average number of prior arrests and 95% confidence interval by race and enrollment status",
    caption = "Source: Cook County State's Attorney's Office"
  ) +
  theme_minimal()
```

### 2.4 Estimate the effect of the program on reducing the likelihood of re-arrest before disposition

One difficulty is that we don't have enough information about the implementation of the program. We are not sure if the program was randomized and how was the compliance.

**1. OLS (or Linear Probability Model)**

The first specification is a "naive" OLS model with robust standard error.
    
$$
		rearrest_{ic} = \tau treat_{ic} + \beta X_{ic} + \beta_4 age_{ic} + \epsilon_{ic}
$$
    
where $i$ is the individual,  $c$ is the case, $X_{ic$ is the vector for race, gender, age, and number of prior arrests. 

It can correctly estimate the treatment effect given that 1) there is no selection on unobservables and we've controlled all observables that could be selected upon; and 2) how people are self-selected based on those variables can be approximated by a linear function. But these assumptions are unlikely to be true. 
    
If the program was a randomized trial, the treatment was administered on the case level, not on the individual level. Hence, we don't cluter standard errors here.

Also, by examining the unique values of `person_id`, we can conclude that for most defendants, they only have one or two cases. Indiviudal fixed effects is not desirable here.

**2. Logit Model**

Assume the program was not an experiment, we can improve our **prediction** on the likelihood by using a logit model instead of a linear probability model, which was implemented in specification 1. But the results given by logit specification is for prediction, not for causal inference.
    
$$
  Pr(rearrest = 1 | X_c) = \frac{exp^{X_c'\beta}}{1 + e^{X_c'\beta}}
$$
where $X_c$ are prior arrests, gender, race, and age of the case $c$. In the logit model the treatment significantly reduces the likelihood of rearrest.


**3. Weighted Propensity Score Matching**

The third specification is a weighted propensity score matching. To estimate the causal effect of this treatment given that the program was observational, not experimental, we still need to assume that there is no selection on unobservables and we've controlled all observables that could be selected upon. But we can relax the assumption on the functional form.

Still, the estimate based upon propensity score matching is not entirely valid, because we omit variables such as grades, household income, etc..

However, this is less restrictive and therefore more plausible than the OLS estimate, and better serves the purpose of causal inference compared to logit estimate.

```{r estimate treatment effect}
# Specification 1: OLS
ols <- lm_robust(re_arrest ~ treat + prior_arrests + male + black + white + age, data = analysis_data)
tb1 <- tbl_regression(ols)

# Specification 2: logit
logit <- glm(re_arrest ~ treat + prior_arrests + male + black + white + age, data = analysis_data, family = binomial)
tb2 <- tbl_regression(logit)

# Specification 3: Propensity score matching (weighting)
pscore_estimate <- glm(treat ~ prior_arrests + male + black + white + age, data = analysis_data, family = binomial)
pscore <- predict(pscore_estimate, type = "response")

analysis_data$pscore <- pscore

analysis_data$ate_weight <- if_else(analysis_data$treat == 1, (1 / analysis_data$pscore), (1 / (1 - analysis_data$pscore)))
analysis_data$atet_weight <- if_else(analysis_data$treat == 1, 1, (analysis_data$pscore / (1 - analysis_data$pscore)))

psm_ate <- glm(re_arrest ~ treat, data = analysis_data, weights = ate_weight, family = binomial)
psm_atet <- glm(re_arrest ~ treat, data = analysis_data, weights = atet_weight, family = binomial)
tb3 <- tbl_regression(psm_ate)
tb4 <- tbl_regression(psm_atet)

# Merge regression table
tbl_merge(list(tb1, tb2, tb3, tb4), tab_spanner = c("OLS ", "Logit", "Matching (ATE)", "Matching (ATET)"))
```

## Conclusion and Discussion

Overall, the treatment significantly reduces the likelihood of re-arrest before disposition. With the information we have, we can conclude that the program is effective and should be expanded or continued, or should be furthered examined with an experiment.

However, please note that the causal inference has much room for improvement. It would have better performance if we can obtain more relevant variables. For example, their grades, household income, neighboorhoods.
